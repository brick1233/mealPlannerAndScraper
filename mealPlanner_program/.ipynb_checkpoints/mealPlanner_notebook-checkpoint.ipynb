{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "421d5dd5",
   "metadata": {},
   "source": [
    "### Functions:\n",
    "- compile list of recipes\n",
    "- open files in the list (set) of recipes\n",
    "- parse ingredient amount and unit from line and add to dict\n",
    "- create weekly folder and populate w/t recipes and shopping list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271370b6",
   "metadata": {},
   "source": [
    "##### Find quantity and unit of ingredient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAmount(amtStr):\n",
    "    \"\"\"\n",
    "    Extracts and converts ingredient amount and unit from a string.\n",
    "\n",
    "    Args:\n",
    "        amnStr: String containing the amount and unit.\n",
    "\n",
    "    Returns:\n",
    "        the amount as a float and the unit as a string.\n",
    "    \"\"\"\n",
    "    # define regex\n",
    "    regex = r\"(\\d+|\\.\\d+)(\\.\\d+\\s+\\d+\\/\\d+|\\.\\d+|\\/\\d+|\\s+\\d+\\/\\d+)?\"\n",
    "\n",
    "    # clean passed string\n",
    "    amtStr = amtStr.strip()\n",
    "    # extract unit and quantity\n",
    "    try:\n",
    "        # find int, float,\n",
    "        amount = re.match(regex, amtStr)\n",
    "        unit = amtStr[(amount.span()[1]+1):]\n",
    "\n",
    "        # convert quantity to float\n",
    "        rawAmnt = amount.group()\n",
    "        if \"/\" and \" \" in rawAmnt:\n",
    "            numer = float(rawAmnt.split(\" \")[1].split(\"/\")[0])\n",
    "            denom = float(rawAmnt.split(\" \")[1].split(\"/\")[1])\n",
    "            amount = float(rawAmnt.split(\" \")[0]) + float(numer/denom)\n",
    "        elif \"/\" in rawAmnt:\n",
    "            numer = float(rawAmnt.split(\"/\")[0])\n",
    "            denom = float(rawAmnt.split(\"/\")[1])\n",
    "            amount = numer/denom\n",
    "        elif \" \" in rawAmnt:\n",
    "            amount = float(rawAmnt.split(\n",
    "                \" \")[0]) + float(rawAmnt.split(\" \")[1])\n",
    "        else:\n",
    "            amount = rawAmnt\n",
    "        # convert to numbers if dozen is unit\n",
    "        if unit == \"DOZEN\":\n",
    "            amount = float(rawAmnt)*12\n",
    "            unit = \"\"\n",
    "\n",
    "        # return quantity and unit\n",
    "        return round(float(amount), 2), unit\n",
    "    except:\n",
    "        amount = amtStr\n",
    "        return round(float(amount), 2), \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc5e6f",
   "metadata": {},
   "source": [
    "##### Find recipe paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2e00b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRecipes(recipeDir):\n",
    "    \"\"\"\n",
    "    Finds all recipe files within a directory.\n",
    "\n",
    "    Args:\n",
    "        recipeDir: Path to the directory containing recipe files.\n",
    "\n",
    "    Returns:\n",
    "        fileNames: A set of paths to the recipe files.\n",
    "    \"\"\"\n",
    "\n",
    "    fileNames = set()\n",
    "    for root, dirs, files in os.walk(recipeDir, topdown=False):\n",
    "        for name in files:\n",
    "            if name.endswith(\".txt\"):\n",
    "                fileNames.add(os.path.join(root, name))\n",
    "    return fileNames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9d2216",
   "metadata": {},
   "source": [
    "##### Read Recipe and Store Ingredients as List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04445039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readRecipe(fileName):\n",
    "    \"\"\"\n",
    "    Reads a recipe file and extracts the ingredients.\n",
    "\n",
    "    Args:\n",
    "        fleName: Path to the recipe file.\n",
    "\n",
    "    Returns:\n",
    "        ingredientList: A list of ingredient strings.\n",
    "    \"\"\"\n",
    "    # Open the recipe\n",
    "    with open(fileName, 'r') as recipe:\n",
    "        # Store the files contents as lists of lines\n",
    "        lines = [line.strip() for line in recipe]\n",
    "\n",
    "    # split the recipe by section\n",
    "    recipeList = [[]]\n",
    "    for x, y in itertools.groupby(lines, lambda z: z == ''):\n",
    "        if x:\n",
    "            recipeList.append([])\n",
    "        recipeList[-1].extend(y)\n",
    "\n",
    "    # remove the delimeters (list comprehension is pretty baller)\n",
    "    recipeList = [[line for line in section if line != '']\n",
    "                  for section in recipeList]\n",
    "\n",
    "    # check to see if ingredients are where expected\n",
    "    # if not where expected, return empty list\n",
    "    if recipeList[1][0].upper() != \"INGREDIENTS:\":\n",
    "        print(\n",
    "            f\"Could not find the ingredient's section for the recipe {recipeList[0][1].upper()}. Recipe files should have ingredients as the second section.\")\n",
    "        ingredientList = []\n",
    "        return ingredientList\n",
    "    # else, return ingredient list\n",
    "    else:\n",
    "        ingredientList = recipeList[1][1:]\n",
    "        return ingredientList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c6a6b",
   "metadata": {},
   "source": [
    "##### Move Weekly Recipes and write shopping list to weekly dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad3e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createWeeklyFolder(recipes, shoppingList, storageDir):\n",
    "    \"\"\"\n",
    "    Creates a new folder with the week's recipes and shopping list.\n",
    "\n",
    "    Args:\n",
    "        recipes: Set of paths to the recipe files.\n",
    "        shoppingList: Dictionary of ingredients and their quantities.\n",
    "        storage_dir: Path to the directory where weekly folders are stored.\n",
    "    \"\"\"\n",
    "    # make newDir (remove if already exits)\n",
    "    newDir = f'{storageDir}/{str(date.today()).split(\" \")[0]}'\n",
    "    if os.path.isdir(newDir):\n",
    "        shutil.rmtree(newDir)\n",
    "\n",
    "    os.mkdir(newDir)\n",
    "    \n",
    "    # iterate over each recipe and copy to newDir\n",
    "    for path in recipes:\n",
    "        # extract recipeName and copy to new dir\n",
    "        recipeName = path.split(\"\\\\\")[-1]\n",
    "        dst = f'{newDir}/{recipeName}'\n",
    "        shutil.copy(path, dst)\n",
    "\n",
    "    # write shoppingList to txt file\n",
    "    with open(f'{newDir}/shoppingList.txt', 'w') as file:\n",
    "        for ingredient, quantity in shoppingList.items():\n",
    "            file.write(f'{ingredient}: {quantity[0]} {quantity[1]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d30943",
   "metadata": {},
   "source": [
    "### Put it all together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d8d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set up imports and directory stuff\n",
    "\"\"\"\n",
    "# Make imports\n",
    "import os\n",
    "import itertools\n",
    "import re\n",
    "import shutil\n",
    "from datetime import datetime as date\n",
    "\n",
    "# Set up imports and directory stuff\n",
    "wd = \n",
    "storageDir = \"mealPlans\"\n",
    "recipeDir = 'recipes'\n",
    "\n",
    "# find the recipes as a set of paths\n",
    "recipeSet = findRecipes(f'{wd}/{recipeDir}')\n",
    "\n",
    "# open each recipe, and store the ingredients used\n",
    "ingredientList = []\n",
    "for recipe in enumerate(recipeSet):\n",
    "    ingredientList.extend(readRecipe(recipe[1]))\n",
    "\n",
    "\n",
    "cleanerDict = {\"tea.*\": \"tsp\", \"table.*\": \"tbs\", \"tbl.*\": \"tbs\",\n",
    "               \"ounce.*\": \"oz\", \"pound.*\": \"lb\", \"\\.\\Z\": \"\",\n",
    "               \"cup.*\": \"cup\"}\n",
    "\n",
    "# standardize the units names and make uppercase\n",
    "for oldStr, newStr in cleanerDict.items():\n",
    "    ingredientList = [re.sub(oldStr, newStr, line, flags=re.IGNORECASE)\n",
    "                      for line in ingredientList]\n",
    "\n",
    "ingredientList = [line.upper() for line in ingredientList]\n",
    "\n",
    "\n",
    "# extract each ingredient, adding ammounts in a dictionary\n",
    "shoppingList = {}\n",
    "for line in ingredientList:\n",
    "\n",
    "    item, quant = line.split(\"-\", maxsplit=1)\n",
    "    amnt, unit = findAmount(quant)\n",
    "\n",
    "    if item.strip() not in shoppingList.keys():\n",
    "        shoppingList[item.strip()] = [amnt, unit.strip()]\n",
    "    else:\n",
    "\n",
    "        shoppingList[item.strip()][0] += amnt\n",
    "\n",
    "# create a folder with the shopping list and recipes\n",
    "createWeeklyFolder(recipeSet, shoppingList, storageDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5e2d41",
   "metadata": {},
   "source": [
    "### Build web scraper\n",
    "- functions to:\n",
    "    - find the website domain ie) verify the html structure\n",
    "    - extract data from html using different tag/attribute combos\n",
    "    - parse the html and return the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae68646",
   "metadata": {},
   "source": [
    "##### Function to find domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c92b557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find the domain of a url\n",
    "def parseDomain(url):\n",
    "    # match for \"www.MATCH.com\"\n",
    "    findDomain = re.search(r\"\\.[A-Za-z0-9]+\\.\", url)\n",
    "\n",
    "    # Access the matched text using group(), else report bad url\n",
    "    if findDomain:\n",
    "        return(findDomain.group()[1:-1])\n",
    "    else:\n",
    "        return(\"bad_url\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aaf799",
   "metadata": {},
   "source": [
    "##### Function to parse html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d2d78cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to parse the ingredients and recipe contained\n",
    "#by a website. htmlKey is a dictionary containing the relevant html tags etc.\n",
    "def parseRecipeSite(url, htmlKey):\n",
    "    #send request and read html if good request\n",
    "    page = requests.get(url) #read page\n",
    "    if page.status_code == 200:\n",
    "        #get the soup\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        \n",
    "        #isolate the text from the website and return\n",
    "        ingredientStr = htmlKey[0][0](soup, htmlKey[0][1])\n",
    "        recipeStr =  htmlKey[1][0](soup, htmlKey[1][1])\n",
    "        return ingredientStr, recipeStr\n",
    "    else:\n",
    "        return f'This url \"{url}\" had a bad request. Error #: {page.status_code}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335908bc",
   "metadata": {},
   "source": [
    "##### Functions to extract data from html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe70bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find all, provide soup and relvant tags\n",
    "def findAll(soup, key):\n",
    "    #isolate the section and run if exists\n",
    "    htmlList = soup.find_all(key[0], key[1])\n",
    "    if htmlList:\n",
    "        data = str()\n",
    "        #add each item to the string and return\n",
    "        for item in htmlList:\n",
    "            # Get text from each tag\n",
    "            data += item.text.strip() + \"\\n\"\n",
    "        return data\n",
    "    else:\n",
    "        return f\"Error with these tags:\\n{key}\\nAnd this soup:\\n{soup}\"\n",
    "\n",
    "#function to find a specific section, then read the text of a certain tag\n",
    "def find_findAll(soup, key):\n",
    "    #find the section\n",
    "    section_container = soup.find(key[0], key[1])\n",
    "    \n",
    "    # If the container is found, find all list items within it and return\n",
    "    if section_container:\n",
    "        data = \"\\n\".join([item.text.strip() for item in section_container.find_all(key[2])])\n",
    "        \n",
    "        return data\n",
    "    else:\n",
    "        return f\"Error with these tags:\\n{key}\\nAnd this soup:\\n{soup}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5067be",
   "metadata": {},
   "source": [
    "##### Function to store scraped recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62dc7243",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def storeScrapedRecipes (file, recipeTuple):\n",
    "\n",
    "    recipeName = file.name.split(\"/\")[-1].split(\".\")[0]\n",
    "    ingredients = re.sub(r\"\\n+\", \"\\n\", recipeTuple[0])\n",
    "    \n",
    "    recipe = re.sub(r\"\\n+\", \"\\n\", recipeTuple[1])\n",
    "    string = \"\"\n",
    "    string += f'Name:\\n{recipeName.replace(\"-\", \" \")}\\n\\n'\n",
    "    string += f'Ingredients:\\n{ingredients}\\n\\n'\n",
    "    string += f'Directions:\\n{recipe}\\n\\n'\n",
    "    string += f'Notes:\\nScraped from a website on {str(date.today()).split(\" \")[0]}\\n\\n'\n",
    "    string += f'Date:\\n{str(date.today()).split(\" \")[0]}'\n",
    "    #file.write(re.sub(\"\\n\",\"\\n\",string))\n",
    "    file.write(string)\n",
    "\n",
    "#with open(f'{newDir}/{\"https://www.allrecipes.com/recipe/26472/the-best-chicken-soup-ever/\".split(\"/\")[-2]}.txt', \"w+\", encoding=\"utf-8\") as file:\n",
    "            \n",
    "            #storeScrapedRecipes(file, (\"testIngre\", \"TestReci\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc26930",
   "metadata": {},
   "source": [
    "##### get urls from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f77a464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRecipeUrls(scrapeFilePath):\n",
    "    try:\n",
    "        with open(scrapeFilePath, \"r\") as file:\n",
    "            # Read lines, strip whitespace, and store in a list\n",
    "            urls = [line.strip() for line in file.readlines()]\n",
    "            # Convert the list to a tuple\n",
    "            return tuple(urls)\n",
    "    except:\n",
    "        print(f\"Error: File '{scrapeFilePath}' not found.\")\n",
    "        return tuple()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b674711",
   "metadata": {},
   "source": [
    "##### Main Web Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d37ac7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime as date\n",
    "\n",
    "#set-up html parsing keys\n",
    "#allrecipes key\n",
    "allRecipe_ingredient = (findAll,('li', {'class':'mntl-structured-ingredients__list-item'}))\n",
    "allRecipe_recipe = (findAll,(\"li\", {\"class\" :\"comp mntl-sc-block mntl-sc-block-startgroup mntl-sc-block-group--LI\"}))\n",
    "\n",
    "#afamilyfeast key\n",
    "familyFeast_ingredient = (find_findAll, ('div', {'class':\"tasty-recipes-ingredients-body\"}, 'li'))\n",
    "familyFeast_recipe = (findAll, ('li', {'id':re.compile(r'instruction-step-*')}))\n",
    "\n",
    "#compile keys in a dictionary of nested tuples\n",
    "htmlKeys = {\"allrecipes\":(allRecipe_ingredient,allRecipe_recipe), \n",
    "            \"afamilyfeast\": (familyFeast_ingredient,familyFeast_recipe),\n",
    "            \"bad_url\": \"\"}\n",
    "\n",
    "#set up folder to house the scraped recipes\n",
    "wd = \"\"\n",
    "scrapedDir = os.path.join(wd, \"scrapedRecipes\")\n",
    "newDir = f'{scrapedDir}/{str(date.today()).split(\" \")[0]}'\n",
    "if os.path.isdir(newDir):\n",
    "    shutil.rmtree(newDir)\n",
    "\n",
    "os.mkdir(newDir)\n",
    "\n",
    "#define web pages of interest\n",
    "#url = 'https://www.allrecipes.com/recipe/26472/the-best-chicken-soup-ever/\\nhttps://www.afamilyfeast.com/strawberry-torte/' \n",
    "#urlList = url.split(\"\\n\")\n",
    "\n",
    "urlTuple = findRecipeUrls(f'{scrapedDir}/recipeURLs.txt')\n",
    "#print(urlTuple)\n",
    "\n",
    "for url in urlTuple:\n",
    "    domain = parseDomain(url)\n",
    "    if domain == \"bad_url\":\n",
    "        htmlKeys[\"bad_url\"] += url +\"\\n\"\n",
    "        print(\"BAD\")\n",
    "    else:\n",
    "        ingredients, recipe = parseRecipeSite(url, htmlKeys[domain])\n",
    "        #print(f'{newDir}/{url.split(\"/\")[-2]}')\n",
    "        with open(f'{newDir}/{url.split(\"/\")[-2]}.txt', \"w+\", encoding=\"utf-8\") as file:\n",
    "            print(\"here\")\n",
    "            storeScrapedRecipes(file, (ingredients, recipe))\n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28bb540",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c7153f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#set-up html parsing keys\n",
    "#allrecipes key\n",
    "allRecipe_ingredient = (findAll,('li', {'class':'mntl-structured-ingredients__list-item'}))\n",
    "allRecipe_recipe = (findAll,(\"li\", {\"class\" :\"comp mntl-sc-block mntl-sc-block-startgroup mntl-sc-block-group--LI\"}))\n",
    "\n",
    "#afamilyfeast key\n",
    "familyFeast_ingredient = (find_findAll, ('div', {'class':\"tasty-recipes-ingredients-body\"}, 'li'))\n",
    "familyFeast_recipe = (findAll, ('li', {'id':re.compile(r'instruction-step-*')}))\n",
    "\n",
    "#compile keys in a dictionary of nested tuples\n",
    "htmlKeys = {\"allrecipes\":(allRecipe_ingredient,allRecipe_recipe), \n",
    "            \"afamilyfeast\": (familyFeast_ingredient,familyFeast_recipe),\n",
    "            \"bad_url\": \"\"}\n",
    "\n",
    "#set up folder to house the scraped recipes\n",
    "wd = \n",
    "scrapedDir = os.path.join(wd, \"scrapedRecipes\")\n",
    "newDir = f'{scrapedDir}/{str(date.today()).split(\" \")[0]}'\n",
    "if os.path.isdir(newDir):\n",
    "    shutil.rmtree(newDir)\n",
    "\n",
    "os.mkdir(newDir)\n",
    "\n",
    "#define web pages of interest\n",
    "#url = 'https://www.allrecipes.com/recipe/26472/the-best-chicken-soup-ever/\\nhttps://www.afamilyfeast.com/strawberry-torte/' \n",
    "#urlList = url.split(\"\\n\")\n",
    "\n",
    "urlTuple = findRecipeUrls(f'{scrapedDir}/recipeURLs.txt')\n",
    "#print(urlTuple)\n",
    "\n",
    "for url in urlTuple:\n",
    "    domain = parseDomain(url)\n",
    "    if domain == \"bad_url\":\n",
    "        htmlKeys[\"bad_url\"] += url +\"\\n\"\n",
    "        print(\"BAD\")\n",
    "    else:\n",
    "        ingredients, recipe = parseRecipeSite(url, htmlKeys[domain])\n",
    "        #print(f'{newDir}/{url.split(\"/\")[-2]}')\n",
    "        with open(f'{newDir}/{url.split(\"/\")[-2]}.txt', \"w+\", encoding=\"utf-8\") as file:\n",
    "            print(\"here\")\n",
    "            storeScrapedRecipes(file, (ingredients, recipe))\n",
    "            \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
